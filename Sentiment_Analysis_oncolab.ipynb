{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Sample Sentiment Analysis.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXphzDxt243h"
      },
      "source": [
        "## Read data and setup model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IFs5bXA243s",
        "outputId": "e29a0d62-5997-4c2c-99a7-f5a34061635b"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import InputExample, InputFeatures\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o9Ebzp52431"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BeHgUM0244B",
        "outputId": "a5b85a7a-e846-4730-9401-f76484e7ddb9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeKUZsdy244C"
      },
      "source": [
        "_____________________________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qrf5mEy244D"
      },
      "source": [
        "URL = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(fname=\"aclImdb_v1.tar.gz\", \n",
        "                                  origin=URL,\n",
        "                                  untar=True,\n",
        "                                  cache_dir='.',\n",
        "                                  cache_subdir='')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGN2ylsh244H",
        "outputId": "8f4c4c76-661c-4818-d0ab-7469c4252825"
      },
      "source": [
        "# The shutil module offers a number of high-level \n",
        "# operations on files and collections of files.\n",
        "import os\n",
        "import shutil\n",
        "# Create main directory path (\"/aclImdb\")\n",
        "main_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "# Create sub directory path (\"/aclImdb/train\")\n",
        "train_dir = os.path.join(main_dir, 'train')\n",
        "# Remove unsup folder since this is a supervised learning task\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)\n",
        "# View the final train folder\n",
        "print(os.listdir(train_dir))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['labeledBow.feat', 'neg', 'pos', 'unsupBow.feat', 'urls_unsup.txt', 'urls_pos.txt', 'urls_neg.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aYCR6X2244W",
        "outputId": "83dac73b-7fa3-47dd-be36-119bfcab8118"
      },
      "source": [
        "# We create a training dataset and a validation \n",
        "# dataset from our \"aclImdb/train\" directory with a 80/20 split.\n",
        "train = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=30000, validation_split=0.2, \n",
        "    subset='training', seed=123)\n",
        "test = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=30000, validation_split=0.2, \n",
        "    subset='validation', seed=123)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "H4OWigBQ244d",
        "outputId": "35dfe462-94eb-43d8-ccc2-76697828436b"
      },
      "source": [
        "for i in train.take(1):\n",
        "  train_feat = i[0].numpy()\n",
        "  train_lab = i[1].numpy()\n",
        "\n",
        "train = pd.DataFrame([train_feat, train_lab]).T\n",
        "train.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
        "train['DATA_COLUMN'] = train['DATA_COLUMN'].str.decode(\"utf-8\")\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATA_COLUMN</th>\n",
              "      <th>LABEL_COLUMN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Canadian director Vincenzo Natali took the art...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I gave this film 10 not because it is a superb...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I admit to being somewhat jaded about the movi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>For a long time, 'The Menagerie' was my favori...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A truly frightening film. Feels as if it were ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         DATA_COLUMN LABEL_COLUMN\n",
              "0  Canadian director Vincenzo Natali took the art...            1\n",
              "1  I gave this film 10 not because it is a superb...            1\n",
              "2  I admit to being somewhat jaded about the movi...            1\n",
              "3  For a long time, 'The Menagerie' was my favori...            1\n",
              "4  A truly frightening film. Feels as if it were ...            0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BZAR4oNO244k",
        "outputId": "2f2668b7-4c85-4e4f-8dec-115e5b804377"
      },
      "source": [
        "for j in test.take(1):\n",
        "  test_feat = j[0].numpy()\n",
        "  test_lab = j[1].numpy()\n",
        "\n",
        "test = pd.DataFrame([test_feat, test_lab]).T\n",
        "test.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
        "test['DATA_COLUMN'] = test['DATA_COLUMN'].str.decode(\"utf-8\")\n",
        "test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATA_COLUMN</th>\n",
              "      <th>LABEL_COLUMN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I can't believe that so much talent can be was...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This movie blows - let's get that straight rig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The saddest thing about this \"tribute\" is that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm only rating this film as a 3 out of pity b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Something surprised me about this movie - it w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         DATA_COLUMN LABEL_COLUMN\n",
              "0  I can't believe that so much talent can be was...            0\n",
              "1  This movie blows - let's get that straight rig...            0\n",
              "2  The saddest thing about this \"tribute\" is that...            0\n",
              "3  I'm only rating this film as a 3 out of pity b...            0\n",
              "4  Something surprised me about this movie - it w...            1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV7K4MXm244m"
      },
      "source": [
        "### Creating Input Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v76IvZx244n",
        "outputId": "6cd2faef-850e-40ae-e218-c95081e3c18c"
      },
      "source": [
        "InputExample(guid=None,\n",
        "             text_a = \"Hello, world\",\n",
        "             text_b = None,\n",
        "             label = 1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InputExample(guid=None, text_a='Hello, world', text_b=None, label=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9q8OZfw244p"
      },
      "source": [
        "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
        "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "                                                          text_a = x[DATA_COLUMN], \n",
        "                                                          text_b = None,\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "                                                          text_a = x[DATA_COLUMN], \n",
        "                                                          text_b = None,\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
        "  \n",
        "  return train_InputExamples, validation_InputExamples\n",
        "\n",
        "#   train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n",
        "#                                                                            test, \n",
        "#                                                                            'DATA_COLUMN', \n",
        "#                                                                            'LABEL_COLUMN')\n",
        "  \n",
        "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
        "    features = [] # -> will hold InputFeatures to be converted later\n",
        "\n",
        "    for e in examples:\n",
        "        # Documentation is really strong for this method, so please take a look at it\n",
        "        input_dict = tokenizer.encode_plus(\n",
        "            e.text_a,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length, # truncates if len(s) > max_length\n",
        "            return_token_type_ids=True,\n",
        "            return_attention_mask=True,\n",
        "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
        "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(\n",
        "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def gen():\n",
        "        for f in features:\n",
        "            yield (\n",
        "                {\n",
        "                    \"input_ids\": f.input_ids,\n",
        "                    \"attention_mask\": f.attention_mask,\n",
        "                    \"token_type_ids\": f.token_type_ids,\n",
        "                },\n",
        "                f.label,\n",
        "            )\n",
        "\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        gen,\n",
        "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
        "        (\n",
        "            {\n",
        "                \"input_ids\": tf.TensorShape([None]),\n",
        "                \"attention_mask\": tf.TensorShape([None]),\n",
        "                \"token_type_ids\": tf.TensorShape([None]),\n",
        "            },\n",
        "            tf.TensorShape([]),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "DATA_COLUMN = 'DATA_COLUMN'\n",
        "LABEL_COLUMN = 'LABEL_COLUMN'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m6yy0j-244s",
        "outputId": "acbd5ab3-7e80-4284-d192-23cb7ccfd354"
      },
      "source": [
        "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\n",
        "\n",
        "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
        "train_data = train_data.shuffle(100).batch(32).repeat(2)\n",
        "\n",
        "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
        "validation_data = validation_data.batch(32)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2111: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L4nqYCk244w",
        "outputId": "3e930502-f970-4f62-8410-2c4ff1593d55"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
        "\n",
        "model.fit(train_data, epochs=2, validation_data=validation_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f6cb39c5670>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f6cb39c5670>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "   1250/Unknown - 1087s 851ms/step - loss: 0.2766 - accuracy: 0.8796WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1250/1250 [==============================] - 1134s 888ms/step - loss: 0.2766 - accuracy: 0.8796 - val_loss: 0.3172 - val_accuracy: 0.8838\n",
            "Epoch 2/2\n",
            "1250/1250 [==============================] - 1109s 887ms/step - loss: 0.0751 - accuracy: 0.9740 - val_loss: 0.5572 - val_accuracy: 0.8734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6bad124150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOAZx0x2244w"
      },
      "source": [
        "pred_sentences = ['This was an awesome movie. I watch it twice my time watching this beautiful movie if I have known it was this good',\n",
        "                  'One of the worst movies of all time. I cannot believe I wasted two hours of my life for this movie']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVpH62FF2440",
        "outputId": "8db876c3-e711-4a20-d692-ab355b313e80"
      },
      "source": [
        "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
        "tf_outputs = model(tf_batch)\n",
        "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
        "labels = [1,0]\n",
        "label = tf.argmax(tf_predictions, axis=1)\n",
        "label = label.numpy()\n",
        "for i in range(len(pred_sentences)):\n",
        "  print(pred_sentences[i], \": \\n\", labels[label[i]])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This was an awesome movie. I watch it twice my time watching this beautiful movie if I have known it was this good : \n",
            " 0\n",
            "One of the worst movies of all time. I cannot believe I wasted two hours of my life for this movie : \n",
            " 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1lh7DQOx2rY"
      },
      "source": [
        "model.save_pretrained(\"model_trained_on_imdb_only_colab\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_IQ-k_qT28A"
      },
      "source": [
        "Load our data and fine tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ManI5wJFqni"
      },
      "source": [
        "def make_predictions(model, tokenizer, pred_sentences, batch_size = 1000):\n",
        "  predictions = []\n",
        "\n",
        "  for ii, sent_batch in enumerate(batch(pred_sentences, batch_size)):\n",
        "    print('Batch', ii)\n",
        "    tf_batch = tokenizer(sent_batch, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
        "    tf_outputs = model(tf_batch)\n",
        "    tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
        "    labels = [0, 1]\n",
        "    label = tf.argmax(tf_predictions, axis=1)\n",
        "    label = label.numpy()\n",
        "\n",
        "    predictions.extend([labels[label[i]] for i in range(len(sent_batch))])\n",
        "  # for i in range(len(pred_sentences)):\n",
        "  #   print(pred_sentences[i], \": \\n\", labels[label[i]])\n",
        "  print(len(predictions), 'predictions made')\n",
        "  return predictions"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nsopN35k5YXu",
        "outputId": "0ce914c9-11e8-41f1-d005-1a3ff164a7d6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def batch(iterable, n = 1):\n",
        "\tcurrent_batch = []\n",
        "\tfor item in iterable:\n",
        "\t    current_batch.append(item)\n",
        "\t    if len(current_batch) == n:\n",
        "\t        yield current_batch\n",
        "\t        current_batch = []\n",
        "\tif current_batch:\n",
        "\t    yield current_batch\n",
        "\n",
        "def deEmojify(text):\n",
        "  regrex_pattern = re.compile(pattern = \"[\"\n",
        "      u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "      u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "      u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "      u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "      u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "      u\"\\U00002702-\\U000027B0\"\n",
        "      u\"\\U00002702-\\U000027B0\"\n",
        "      u\"\\U000024C2-\\U0001F251\"\n",
        "      u\"\\U0001f926-\\U0001f937\"\n",
        "      u\"\\U00010000-\\U0010ffff\"\n",
        "      u\"\\u2640-\\u2642\" \n",
        "      u\"\\u2600-\\u2B55\"\n",
        "      u\"\\u200d\"\n",
        "      u\"\\u23cf\"\n",
        "      u\"\\u23e9\"\n",
        "      u\"\\u231a\"\n",
        "      u\"\\ufe0f\"  # dingbats\n",
        "      u\"\\u3030\"\n",
        "                          \"]+\", flags = re.UNICODE)\n",
        "  return regrex_pattern.sub(r'',text)\n",
        "    \n",
        "\n",
        "training_data = pd.read_csv('Training_Dataset.csv')\n",
        "training_data['inverted_label'] = np.where(training_data.label.values==0,1,0)\n",
        "training_data['text_no_emoji'] = [deEmojify(x) for x in training_data.text.values]\n",
        "training_data['char_length'] = training_data.text_no_emoji.str.len()\n",
        "\n",
        "# Split train and validation data\n",
        "train_df, validation_df = train_test_split(training_data, test_size=0.25)\n",
        "\n",
        "\n",
        "competition_test = pd.read_csv('Test_Dataset.csv')\n",
        "competition_test['text_no_emoji'] = [deEmojify(x) for x in competition_test.text.values]\n",
        "# competition_test['text'] = competition_test['text'].str.decode(\"utf-8\")\n",
        "training_data.head(42)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>inverted_label</th>\n",
              "      <th>text_no_emoji</th>\n",
              "      <th>char_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18822638</td>\n",
              "      <td>I should have known better, its obviously not ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I should have known better, its obviously not ...</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9f9f1c3f</td>\n",
              "      <td>I am happy for you. No, seriously, I am.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I am happy for you. No, seriously, I am.</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>563242ec</td>\n",
              "      <td>Everyone including an ambassador has freedom o...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Everyone including an ambassador has freedom o...</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ceda51ca</td>\n",
              "      <td>Oh really?</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Oh really?</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bfb0c83d</td>\n",
              "      <td>Thanks for reply, I'll enjoy reading through t...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Thanks for reply, I'll enjoy reading through t...</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3f49cfe8</td>\n",
              "      <td>Threatening to jail disadvantaged families is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Threatening to jail disadvantaged families is ...</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ca196d3e</td>\n",
              "      <td>Is her fake chin totally to the right of where...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Is her fake chin totally to the right of where...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>f766effa</td>\n",
              "      <td>My man!</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>My man!</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2688d61b</td>\n",
              "      <td>Is that a little poot at :09?</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Is that a little poot at :09?</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a2f2bb80</td>\n",
              "      <td>I believe you copied and paste from somewhere ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I believe you copied and paste from somewhere ...</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0f5b3081</td>\n",
              "      <td>Way too fancy</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Way too fancy</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>f7f08a01</td>\n",
              "      <td>Hey! Anyone have the DL on this MLM ? Would lo...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Hey! Anyone have the DL on this MLM ? Would lo...</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>85e80a4f</td>\n",
              "      <td>I don‚Äôt like Sean Edwards As I love the 2nd am...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I don‚Äôt like Sean Edwards As I love the 2nd am...</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>8510d074</td>\n",
              "      <td>Michael Holt I hate this man</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Michael Holt I hate this man</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>f5c07d3a</td>\n",
              "      <td>its disgusting where our society is. free tube...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>its disgusting where our society is. free tube...</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>e7889293</td>\n",
              "      <td>oops, my bad.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>oops, my bad.</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>c060f8cf</td>\n",
              "      <td>Hopefully you don't come across too many crews...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Hopefully you don't come across too many crews...</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ec912a6f</td>\n",
              "      <td>I know, I know. I wish Reptile had a better fa...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I know, I know. I wish Reptile had a better fa...</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>80efe4cc</td>\n",
              "      <td>And that's an issue. Councils are *so* unrepre...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>And that's an issue. Councils are *so* unrepre...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>615926b9</td>\n",
              "      <td>I‚Äôm surprised alcohol isn‚Äôt entirely sold by t...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I‚Äôm surprised alcohol isn‚Äôt entirely sold by t...</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>d6f78932</td>\n",
              "      <td>Is this furry_irls equivalent of a tik tok? An...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Is this furry_irls equivalent of a tik tok? An...</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>a6e8f9f6</td>\n",
              "      <td>Sorry man Mitchell Phillips doesnt care about ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sorry man Mitchell Phillips doesnt care about ...</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>a1ff361a</td>\n",
              "      <td>That's the funniest mental image I've had in a...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>That's the funniest mental image I've had in a...</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>61b650fc</td>\n",
              "      <td>Imagine finding that in your bed</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Imagine finding that in your bed</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>9cf5d9cd</td>\n",
              "      <td>i dont know the system cause i never speak a w...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>i dont know the system cause i never speak a w...</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>625de2df</td>\n",
              "      <td>Such an ignorant comment, his reasoning is pub...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Such an ignorant comment, his reasoning is pub...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>46ddfc8d</td>\n",
              "      <td>I gave up on the show over and over before I a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I gave up on the show over and over before I a...</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>a5f87552</td>\n",
              "      <td>That's different lol.. And any positive, faint...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>That's different lol.. And any positive, faint...</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0620e612</td>\n",
              "      <td>Wow - it would be great to have an AMA about w...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Wow - it would be great to have an AMA about w...</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0ceeab3b</td>\n",
              "      <td>Welcome. We eat our own.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Welcome. We eat our own.</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>282dfbbf</td>\n",
              "      <td>Thanks, but to my mind, I had no choice. My ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Thanks, but to my mind, I had no choice. My ma...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>342a4923</td>\n",
              "      <td>The US and Canada are great allies, it's reall...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>The US and Canada are great allies, it's reall...</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5146a053</td>\n",
              "      <td>But at least you could Get to Tina Smith more ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>But at least you could Get to Tina Smith more ...</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>f09a17f5</td>\n",
              "      <td>Eh, same difference</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Eh, same difference</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>57a7e668</td>\n",
              "      <td>I like #5 too she is slacking on her end of th...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I like #5 too she is slacking on her end of th...</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>08c605c5</td>\n",
              "      <td>Say it with me now: WE üëèLOVE üëèPAT üëèC üëèAND üëèWE ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Say it with me now: WE LOVE PAT C AND WE DON‚ÄôT...</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0104aea5</td>\n",
              "      <td>So insightful!</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>So insightful!</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>fa535252</td>\n",
              "      <td>This guy doesn‚Äôt know how to life...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>This guy doesn‚Äôt know how to life...</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>944e513a</td>\n",
              "      <td>Amazing device... Wish I had one growing up in...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Amazing device... Wish I had one growing up in...</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5459eca2</td>\n",
              "      <td>This is straight up depressing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>This is straight up depressing</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>764f4b9e</td>\n",
              "      <td>I had to put Bird Box because it's the only di...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I had to put Bird Box because it's the only di...</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0d5ef4a3</td>\n",
              "      <td>Facechat. Fax. Oh mama</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Facechat. Fax. Oh mama</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  ... char_length\n",
              "0   18822638  ...          94\n",
              "1   9f9f1c3f  ...          40\n",
              "2   563242ec  ...          73\n",
              "3   ceda51ca  ...          10\n",
              "4   bfb0c83d  ...          94\n",
              "5   3f49cfe8  ...          77\n",
              "6   ca196d3e  ...          65\n",
              "7   f766effa  ...           7\n",
              "8   2688d61b  ...          29\n",
              "9   a2f2bb80  ...         150\n",
              "10  0f5b3081  ...          13\n",
              "11  f7f08a01  ...          78\n",
              "12  85e80a4f  ...          71\n",
              "13  8510d074  ...          28\n",
              "14  f5c07d3a  ...          70\n",
              "15  e7889293  ...          13\n",
              "16  c060f8cf  ...         117\n",
              "17  ec912a6f  ...          50\n",
              "18  80efe4cc  ...          65\n",
              "19  615926b9  ...          93\n",
              "20  d6f78932  ...         131\n",
              "21  a6e8f9f6  ...          81\n",
              "22  a1ff361a  ...          62\n",
              "23  61b650fc  ...          32\n",
              "24  9cf5d9cd  ...         109\n",
              "25  625de2df  ...          74\n",
              "26  46ddfc8d  ...         103\n",
              "27  a5f87552  ...          69\n",
              "28  0620e612  ...         129\n",
              "29  0ceeab3b  ...          24\n",
              "30  282dfbbf  ...          74\n",
              "31  342a4923  ...          85\n",
              "32  5146a053  ...          54\n",
              "33  f09a17f5  ...          20\n",
              "34  57a7e668  ...         115\n",
              "35  08c605c5  ...          62\n",
              "36  0104aea5  ...          14\n",
              "37  fa535252  ...          36\n",
              "38  944e513a  ...          87\n",
              "39  5459eca2  ...          30\n",
              "40  764f4b9e  ...          90\n",
              "41  0d5ef4a3  ...          22\n",
              "\n",
              "[42 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKtJjKXXRvg2",
        "outputId": "84835022-db3d-45e9-b69a-9050193c8f30"
      },
      "source": [
        "# print(\"Total training data: \", training_data.shape)\n",
        "# print(\"Train Split: \", train_df.shape)\n",
        "# print(\"Validation Split: \", validation_df.shape)\n",
        "# print(\"Competition Test Data: \", competition_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training data:  (24309, 5)\n",
            "Train Split:  (18231, 5)\n",
            "Validation Split:  (6078, 5)\n",
            "Competition Test Data:  (10419, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKqzbqZSQzp_"
      },
      "source": [
        "# training_data['inverted_predicted_label'] = make_predictions(model, tokenizer, list(training_data['text_no_emoji'].values), batch_size = 500)\n",
        "# training_data['inverted_label'] = np.where(training_data.label.values==0,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e_OMwjfxK7T",
        "outputId": "85af5033-d041-472c-a58a-43063c824ff8"
      },
      "source": [
        "# print(classification_report(training_data['label'], training_data['predicted_label']))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.63      0.74     19190\n",
            "           1       0.34      0.73      0.46      5119\n",
            "\n",
            "    accuracy                           0.65     24309\n",
            "   macro avg       0.62      0.68      0.60     24309\n",
            "weighted avg       0.78      0.65      0.68     24309\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWzYkSDBRWKQ"
      },
      "source": [
        "# competition_test['predicted_label'] = make_predictions(model, tokenizer, list(competition_test['text_no_emoji'].values))\n",
        "# competition_test[['ID', 'label']].to_csv('ber_based_submission_1_imdb_only_trained.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FASFeXtn2440"
      },
      "source": [
        "_____________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6XH4bfAyis0"
      },
      "source": [
        "Train additionally on our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9weh1ygK0Nwv"
      },
      "source": [
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'inverted_label'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phTpZrXyyfbz",
        "outputId": "16f18fe9-c79c-4e14-b771-125855013b13"
      },
      "source": [
        "train_InputExamples, validation_InputExamples = convert_data_to_examples(train_df, validation_df, DATA_COLUMN, LABEL_COLUMN)\n",
        "\n",
        "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
        "train_data = train_data.shuffle(100).batch(32).repeat(2)\n",
        "\n",
        "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
        "validation_data = validation_data.batch(32)\n",
        "\n",
        "model.fit(train_data, epochs=1, validation_data=validation_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2111: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1140/1140 [==============================] - 972s 852ms/step - loss: 0.2872 - accuracy: 0.8741 - val_loss: 0.3422 - val_accuracy: 0.8616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6bad145a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V69mBTCpyzXk"
      },
      "source": [
        "model.save_pretrained(\"ep1_model_trained_on_imdb_plus_our_data_colab_corrected\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji_AFMdpyxkj",
        "outputId": "6c065ae4-a13c-440a-d58b-096e0fea2ee8"
      },
      "source": [
        "validation_df['inverted_predicted_label'] = make_predictions(model, tokenizer, list(validation_df['text_no_emoji'].values), batch_size = 800)\n",
        "validation_df['predicted_label'] = np.where(validation_df.inverted_predicted_label.values==0,1,0)\n",
        "print(classification_report(validation_df['label'], validation_df['predicted_label']))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0\n",
            "Batch 1\n",
            "Batch 2\n",
            "Batch 3\n",
            "Batch 4\n",
            "Batch 5\n",
            "Batch 6\n",
            "Batch 7\n",
            "6078 predictions made\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91      4765\n",
            "           1       0.71      0.60      0.65      1313\n",
            "\n",
            "    accuracy                           0.86      6078\n",
            "   macro avg       0.80      0.77      0.78      6078\n",
            "weighted avg       0.86      0.86      0.86      6078\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "ww0SLBYI8nET",
        "outputId": "dc76dcc4-1dd2-4e54-a981-408258afa308"
      },
      "source": [
        "validation_df[validation_df.label!=validation_df.predicted_label].head(20)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>inverted_label</th>\n",
              "      <th>text_no_emoji</th>\n",
              "      <th>char_length</th>\n",
              "      <th>inverted_predicted_label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19238</th>\n",
              "      <td>69f38458</td>\n",
              "      <td>He is warped by porn. He's got a problem</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>He is warped by porn. He's got a problem</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4567</th>\n",
              "      <td>ae71c41f</td>\n",
              "      <td>I didn‚Äôt like that blue &amp; yellow until you sai...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I didn‚Äôt like that blue &amp; yellow until you sai...</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15784</th>\n",
              "      <td>8f118d21</td>\n",
              "      <td>Too bad he endorses seiko, this wouldve been a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Too bad he endorses seiko, this wouldve been a...</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4158</th>\n",
              "      <td>de685e76</td>\n",
              "      <td>Exactly! How dare we give those people shade!</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Exactly! How dare we give those people shade!</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1282</th>\n",
              "      <td>01ddbbf4</td>\n",
              "      <td>Once they saw the purple hair dye go into the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Once they saw the purple hair dye go into the ...</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2825</th>\n",
              "      <td>d8f5805b</td>\n",
              "      <td>Which is fair. But they're not respecting you.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Which is fair. But they're not respecting you.</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10875</th>\n",
              "      <td>39bb5f7e</td>\n",
              "      <td>Terrifyingly accurate bot</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Terrifyingly accurate bot</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7479</th>\n",
              "      <td>dbc6dcf2</td>\n",
              "      <td>Google image him. Hes NEVER had a good haircut.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Google image him. Hes NEVER had a good haircut.</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24150</th>\n",
              "      <td>a9fd557a</td>\n",
              "      <td>Believe me when i say not having a job doesn't...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Believe me when i say not having a job doesn't...</td>\n",
              "      <td>135</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20208</th>\n",
              "      <td>37a0b2a1</td>\n",
              "      <td>Whatever it is, not enough.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Whatever it is, not enough.</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1353</th>\n",
              "      <td>a07448f2</td>\n",
              "      <td>The right time would have been never being the...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>The right time would have been never being the...</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13924</th>\n",
              "      <td>617491a0</td>\n",
              "      <td>What the hell. Poor Amanda Stanley MD. Poor yo...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>What the hell. Poor Amanda Stanley MD. Poor yo...</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2684</th>\n",
              "      <td>6d332bea</td>\n",
              "      <td>Not quite sure what was really dickish about m...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Not quite sure what was really dickish about m...</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6317</th>\n",
              "      <td>c6fde3e5</td>\n",
              "      <td>To bad we aren‚Äôt getting Mary Lester vs Mary L...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>To bad we aren‚Äôt getting Mary Lester vs Mary L...</td>\n",
              "      <td>139</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7028</th>\n",
              "      <td>f360ec99</td>\n",
              "      <td>One can only hope this is the worst issue you ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>One can only hope this is the worst issue you ...</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19804</th>\n",
              "      <td>17160715</td>\n",
              "      <td>Have thought most of the game was OK with some...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Have thought most of the game was OK with some...</td>\n",
              "      <td>93</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10285</th>\n",
              "      <td>5666d5ed</td>\n",
              "      <td>I think Kelsey Wallace is honestly just a whac...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I think Kelsey Wallace is honestly just a whac...</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23506</th>\n",
              "      <td>0683a65e</td>\n",
              "      <td>If you don‚Äôt include AZ in your 3, you‚Äôre wrong.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>If you don‚Äôt include AZ in your 3, you‚Äôre wrong.</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12487</th>\n",
              "      <td>88338d34</td>\n",
              "      <td>Don't get excited yet...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Don't get excited yet...</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6026</th>\n",
              "      <td>70e1f0c7</td>\n",
              "      <td>Yep, they expect you to revolve around them, b...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yep, they expect you to revolve around them, b...</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  ... predicted_label\n",
              "19238  69f38458  ...               0\n",
              "4567   ae71c41f  ...               0\n",
              "15784  8f118d21  ...               0\n",
              "4158   de685e76  ...               1\n",
              "1282   01ddbbf4  ...               1\n",
              "2825   d8f5805b  ...               0\n",
              "10875  39bb5f7e  ...               1\n",
              "7479   dbc6dcf2  ...               0\n",
              "24150  a9fd557a  ...               0\n",
              "20208  37a0b2a1  ...               1\n",
              "1353   a07448f2  ...               0\n",
              "13924  617491a0  ...               1\n",
              "2684   6d332bea  ...               1\n",
              "6317   c6fde3e5  ...               0\n",
              "7028   f360ec99  ...               1\n",
              "19804  17160715  ...               0\n",
              "10285  5666d5ed  ...               0\n",
              "23506  0683a65e  ...               0\n",
              "12487  88338d34  ...               1\n",
              "6026   70e1f0c7  ...               0\n",
              "\n",
              "[20 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Xvbc8GTUa0",
        "outputId": "b8af062d-a4b8-4d87-d01c-04aff77102cb"
      },
      "source": [
        "competition_test['inverted_label'] = make_predictions(model, tokenizer, list(competition_test['text_no_emoji'].values))\n",
        "competition_test['label'] = np.where(competition_test.inverted_label.values==0,1,0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0\n",
            "Batch 1\n",
            "Batch 2\n",
            "Batch 3\n",
            "Batch 4\n",
            "Batch 5\n",
            "Batch 6\n",
            "Batch 7\n",
            "Batch 8\n",
            "Batch 9\n",
            "Batch 10\n",
            "10419 predictions made\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2hgwaam_VqI"
      },
      "source": [
        "competition_test[['ID', 'label']].to_csv('bert_based_imdb_plus_our_data_colab_correctly_trained_1epoch.csv',index=False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUW6wn1SNNad",
        "outputId": "aeedff47-0ff3-4f06-b03e-c3045eb5e62c"
      },
      "source": [
        "model.fit(train_data, epochs=1, validation_data=validation_data)\n",
        "model.save_pretrained(\"ep2_model_trained_on_imdb_plus_our_data_colab_corrected\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1140/1140 [==============================] - 971s 852ms/step - loss: 0.0847 - accuracy: 0.9676 - val_loss: 0.6467 - val_accuracy: 0.8467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW0mVXaPOiln",
        "outputId": "997fefaf-23db-4f84-8a6f-5b12eec529a1"
      },
      "source": [
        "validation_df['inverted_predicted_label'] = make_predictions(model, tokenizer, list(validation_df['text_no_emoji'].values), batch_size = 800)\n",
        "validation_df['predicted_label'] = np.where(validation_df.inverted_predicted_label.values==0,1,0)\n",
        "print(classification_report(validation_df['label'], validation_df['predicted_label']))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0\n",
            "Batch 1\n",
            "Batch 2\n",
            "Batch 3\n",
            "Batch 4\n",
            "Batch 5\n",
            "Batch 6\n",
            "Batch 7\n",
            "6078 predictions made\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90      4765\n",
            "           1       0.66      0.60      0.63      1313\n",
            "\n",
            "    accuracy                           0.85      6078\n",
            "   macro avg       0.78      0.76      0.77      6078\n",
            "weighted avg       0.84      0.85      0.84      6078\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JphDfAQPO0R1",
        "outputId": "3438e1be-9626-454a-f4dd-d9d8b0d16f11"
      },
      "source": [
        "competition_test['inverted_label'] = make_predictions(model, tokenizer, list(competition_test['text_no_emoji'].values))\n",
        "competition_test['label'] = np.where(competition_test.inverted_label.values==0,1,0)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0\n",
            "Batch 1\n",
            "Batch 2\n",
            "Batch 3\n",
            "Batch 4\n",
            "Batch 5\n",
            "Batch 6\n",
            "Batch 7\n",
            "Batch 8\n",
            "Batch 9\n",
            "Batch 10\n",
            "10419 predictions made\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkLEdVBFOeZc"
      },
      "source": [
        "competition_test[['ID', 'label']].to_csv('3_bert_based_imdb_plus_our_data_colab_correctly_trained_2epoch.csv',index=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YsHuBiW9NLN",
        "outputId": "759708f7-76a9-4e38-c3c1-4baa73367611"
      },
      "source": [
        "def is_camel_case(s):\n",
        "  if s != s.lower() and s != s.upper() and \"_\" not in s and sum(i.isupper() for i in s[1:-1]) == 1:\n",
        "      return True\n",
        "  return False"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}